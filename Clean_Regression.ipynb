{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emd\n",
    "import pylab as plt\n",
    "import statsmodels.api as sm\n",
    "import plotly.express as px\n",
    "import os\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_regress(combined_data, country, \n",
    "        low_pass_percent=0.2, med_pass_percent=0.5, high_pass_percent=0.8):\n",
    "        \n",
    "        combined_data = combined_data[[\"Last Price\", \"Price\", \"Actual\"]]\n",
    "        combined_data = combined_data.dropna(axis=0)\n",
    "        elec_price = combined_data[\"Price\"].to_numpy()\n",
    "        lng_price = combined_data[\"Last Price\"].to_numpy()\n",
    "        demand = combined_data[\"Actual\"].to_numpy()\n",
    "        # plot and transform all of the data for electricity pricing\n",
    "        #plt.figure()\n",
    "        #plt.plot(elec_price, \"k\")\n",
    "\n",
    "        imf, noise = emd.sift.complete_ensemble_sift(elec_price, ensemble_noise=1)\n",
    "        # create the pass thresholds based on the input percentages\n",
    "        low_pass_thresh_elec = int(np.ceil(low_pass_percent * imf.shape[1]))\n",
    "        med_pass_thresh_elec = int(np.ceil(med_pass_percent * imf.shape[1]))\n",
    "        high_pass_thresh_elec = int(np.ceil(high_pass_percent * imf.shape[1]))\n",
    "        #emd.plotting.plot_imfs(imf)\n",
    "\n",
    "        IP, IF, IA = emd.spectra.frequency_transform(imf, 256, \"hilbert\")\n",
    "        # plot and transform all of the data for LNG prices\n",
    "        #plt.figure()\n",
    "        #plt.plot(lng_price, \"k\")\n",
    "\n",
    "        lng_imf, lng_noise = emd.sift.complete_ensemble_sift(lng_price, ensemble_noise=1)\n",
    "        low_pass_thresh_lng = int(np.ceil(low_pass_percent * lng_imf.shape[1]))\n",
    "        med_pass_thresh_lng = int(np.ceil(med_pass_percent * lng_imf.shape[1]))\n",
    "        high_pass_thresh_lng = int(np.ceil(high_pass_percent * lng_imf.shape[1]))\n",
    "\n",
    "        #emd.plotting.plot_imfs(lng_imf)\n",
    "\n",
    "        IP, IF, IA = emd.spectra.frequency_transform(imf, 256, \"hilbert\")\n",
    "\n",
    "        demand_imf, demand_noise = emd.sift.complete_ensemble_sift(demand, ensemble_noise=1)\n",
    "        low_pass_thresh_demand = int(np.ceil(low_pass_percent * demand_imf.shape[1]))\n",
    "        med_pass_thresh_demand = int(np.ceil(med_pass_percent * demand_imf.shape[1]))\n",
    "        high_pass_thresh_demand = int(np.ceil(high_pass_percent * demand_imf.shape[1]))\n",
    "        \n",
    "        low_pass_elec = imf[:, low_pass_thresh_elec:]\n",
    "        low_pass_means_elec = np.apply_along_axis(np.mean, 1, low_pass_elec)\n",
    "        print(low_pass_means_elec)\n",
    "        print(np.log(low_pass_means_elec+5))\n",
    "        low_pass_lng = lng_imf[:, low_pass_thresh_lng:]\n",
    "        low_pass_means_lng = np.apply_along_axis(np.mean, 1, low_pass_lng)\n",
    "\n",
    "        low_pass_demand = demand_imf[:, low_pass_thresh_demand:]\n",
    "        low_pass_means_demand = np.apply_along_axis(np.mean, 1, low_pass_demand)\n",
    "\n",
    "        #px.scatter(x=low_pass_means_elec, y=low_pass_means_lng)\n",
    "\n",
    "\n",
    "        med_pass_elec = imf[:, med_pass_thresh_elec:]\n",
    "        med_pass_means_elec = np.apply_along_axis(np.mean, 1, med_pass_elec)\n",
    "\n",
    "        med_pass_lng = lng_imf[:, med_pass_thresh_lng:]\n",
    "        med_pass_means_lng = np.apply_along_axis(np.mean, 1, med_pass_lng)\n",
    "\n",
    "        med_pass_demand = demand_imf[:, med_pass_thresh_demand:]\n",
    "        med_pass_means_demand = np.apply_along_axis(np.mean, 1, med_pass_demand)\n",
    "\n",
    "        #px.scatter(x=med_pass_means_elec, y=med_pass_means_lng)\n",
    "        \n",
    "        high_pass_elec = imf[:, high_pass_thresh_elec:]\n",
    "        high_pass_means_elec = np.apply_along_axis(np.mean, 1, high_pass_elec)\n",
    "\n",
    "        high_pass_lng = lng_imf[:, high_pass_thresh_lng:]\n",
    "        high_pass_means_lng = np.apply_along_axis(np.mean, 1, high_pass_lng)\n",
    "\n",
    "        high_pass_demand = lng_imf[:, high_pass_thresh_demand:]\n",
    "        high_pass_means_demand = np.apply_along_axis(np.mean, 1, high_pass_demand)\n",
    "        \n",
    "        #px.scatter(x=high_pass_means_elec, y=high_pass_means_lng)\n",
    "        X_low = pd.DataFrame({\"LNG\": low_pass_means_lng, \"Demand\": low_pass_means_demand})\n",
    "        X_low_log = X_low.copy()\n",
    "        X_low_log[\"LNG\"] = X_low_log[\"LNG\"].apply(lambda x: np.log(x+np.min(X_low_log[\"LNG\"])+1))\n",
    "        low_model = linear_model.LinearRegression().fit(X_low_log, np.log(low_pass_means_elec+np.min(low_pass_means_elec)+1))\n",
    "        print(\"Low pass LNG coefficient = {}, Demand Coefficient = {}\".format(low_model.coef_[0], low_model.coef_[1]))\n",
    "\n",
    "        X_med = pd.DataFrame({\"LNG\": med_pass_means_lng, \"Demand\": med_pass_means_demand})\n",
    "        X_med_log = X_med.copy()\n",
    "        X_med_log[\"LNG\"] = X_med_log[\"LNG\"].apply(lambda x: np.log(x+np.min(X_med_log[\"LNG\"])+1))\n",
    "        med_model = linear_model.LinearRegression().fit(X_med_log, np.log(med_pass_means_elec + np.min(med_pass_means_elec)+1))\n",
    "        print(\"Med Pass coefficient = {}, Demand Coefficient\".format(med_model.coef_[0], med_model.coef_[1]))\n",
    "\n",
    "        X_high = pd.DataFrame({\"LNG\": high_pass_means_lng, \"Demand\": high_pass_means_demand})\n",
    "        X_high_log = X_high.copy()\n",
    "        X_high_log[\"LNG\"] = X_high_log[\"LNG\"].apply(lambda x: np.log(x + np.min(X_high_log[\"LNG\"])+1))\n",
    "        high_model = linear_model.LinearRegression().fit(X_high_log, np.log(high_pass_means_elec + np.min(high_pass_means_elec) + 1))\n",
    "        print(\"High Pass coefficient = {},  Demand Coefficent = {}\".format(high_model.coef_[0], high_model.coef_[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00486442 -2.01295893 -0.05603892 ... -2.58023397 -2.2264746\n",
      " -2.25025613]\n",
      "[ 1.10023245 -0.01304363  1.07975598 ... -0.8680578  -0.25679677\n",
      " -0.28802364]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/b0w9hfrj7t7btyk9h00r0ck40000gn/T/ipykernel_52653/735807060.py:42: RuntimeWarning: invalid value encountered in log\n",
      "  print(np.log(low_pass_means_elec+3))\n",
      "/var/folders/0p/b0w9hfrj7t7btyk9h00r0ck40000gn/T/ipykernel_52653/735807060.py:76: RuntimeWarning: invalid value encountered in log\n",
      "  low_model = linear_model.LinearRegression().fit(X_low_log, np.log(low_pass_means_elec+np.min(low_pass_means_elec)+1))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filter_and_regress(pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./Data/Spain/combined_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mSpain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[82], line 76\u001b[0m, in \u001b[0;36mfilter_and_regress\u001b[0;34m(combined_data, country, low_pass_percent, med_pass_percent, high_pass_percent)\u001b[0m\n\u001b[1;32m     74\u001b[0m X_low_log \u001b[39m=\u001b[39m X_low\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     75\u001b[0m X_low_log[\u001b[39m\"\u001b[39m\u001b[39mLNG\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m X_low_log[\u001b[39m\"\u001b[39m\u001b[39mLNG\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mlog(x\u001b[39m+\u001b[39mnp\u001b[39m.\u001b[39mmin(X_low_log[\u001b[39m\"\u001b[39m\u001b[39mLNG\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 76\u001b[0m low_model \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39;49mLinearRegression()\u001b[39m.\u001b[39;49mfit(X_low_log, np\u001b[39m.\u001b[39;49mlog(low_pass_means_elec\u001b[39m+\u001b[39;49mnp\u001b[39m.\u001b[39;49mmin(low_pass_means_elec)\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     77\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLow pass LNG coefficient = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Demand Coefficient = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(low_model\u001b[39m.\u001b[39mcoef_[\u001b[39m0\u001b[39m], low_model\u001b[39m.\u001b[39mcoef_[\u001b[39m1\u001b[39m]))\n\u001b[1;32m     79\u001b[0m X_med \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mLNG\u001b[39m\u001b[39m\"\u001b[39m: med_pass_means_lng, \u001b[39m\"\u001b[39m\u001b[39mDemand\u001b[39m\u001b[39m\"\u001b[39m: med_pass_means_demand})\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/linear_model/_base.py:649\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    645\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[1;32m    647\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 649\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    650\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    651\u001b[0m )\n\u001b[1;32m    653\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    654\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    655\u001b[0m )\n\u001b[1;32m    657\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[1;32m    658\u001b[0m     X,\n\u001b[1;32m    659\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    663\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/utils/validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[0;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1105\u001b[0m     X,\n\u001b[1;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1118\u001b[0m )\n\u001b[1;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/utils/validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 919\u001b[0m         _assert_all_finite(\n\u001b[1;32m    920\u001b[0m             array,\n\u001b[1;32m    921\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    922\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    923\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    924\u001b[0m         )\n\u001b[1;32m    926\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "filter_and_regress(pd.read_csv(\"./Data/Spain/combined_data.csv\"), \"Spain\")\n",
    "#data = pd.read_csv(\"./Data/Germany/combined.csv\")\n",
    "#filter_and_regress(data, \"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run regressions based on the timescales of COVID and war in Ukraine\n",
    "def timeperiod_differences(combined_data_path, country_name):\n",
    "        # these serve as best guesses, change at will\n",
    "        COVID_START = \"2020-03-01\"\n",
    "        WAR_START = \"2022-02-01\"\n",
    "\n",
    "        # read in the data from the combined dataset\n",
    "        data = pd.read_csv(combined_data_path)\n",
    "        data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "        pre_covid = data[data[\"Date\"] < COVID_START]\n",
    "\n",
    "        covid = data[data[\"Date\"] > COVID_START]\n",
    "        covid = covid[covid[\"Date\"] < WAR_START]\n",
    "\n",
    "        war = data[data[\"Date\"] > WAR_START]\n",
    "\n",
    "        # run the regressions on the given datasets\n",
    "        print(\"Pre-COVID in {}\".format(country_name))\n",
    "        filter_and_regress(pre_covid, country_name)\n",
    "\n",
    "        print(\"COVID Era in {}\".format(country_name))\n",
    "        filter_and_regress(covid, country_name, med_pass_threshold=8, high_pass_threshold=11)\n",
    "\n",
    "        print(\"War in Ukraine Era in {}\".format(country_name))\n",
    "        filter_and_regress(war, country_name, med_pass_threshold=6, high_pass_threshold=9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-COVID in Spain\n",
      "Low pass coefficient = 2.4450979909396375\n",
      "Med Pass coefficient = 2.443228107736556\n",
      "High Pass coefficient = 2.45101590117428\n",
      "COVID Era in Spain\n",
      "Low pass coefficient = 2.02079257747762\n",
      "Med Pass coefficient = 1.973463297130555\n",
      "High Pass coefficient = 1.946029828940902\n",
      "War in Ukraine Era in Spain\n",
      "Low pass coefficient = 1.5160641031776962\n",
      "Med Pass coefficient = 1.5153160382040447\n",
      "High Pass coefficient = 1.5129364671372045\n"
     ]
    }
   ],
   "source": [
    "timeperiod_differences(\"./Data/Spain/combined_data.csv\", \"Spain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06fe89a5f4e9a3ac2ecb86ca59945e3632fbd62854f53839f6675029cf8e446f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
